## 关于测试

由于我们修改了 `embedding.cc` 函数中的类的签名，因此原有的 `embedding_test.cc`（以及一些其它的测试）无法工作。

## 并发设计

我们使用了比较激进的并发策略，具体执行方式如下：

1. 首先遍历一遍所有指令，把指令 parse 成 `std::variant<InitTask, UpdateTask, RecommendTask>` 的数据结构。如果这个指令不属于某个 epoch，那么放入 `std::vector<Task> normal_tasks` 中，如果属于某个 epoch，那么放入 `std::map<int, std::vector<Task>> tasks_in_epoch` 的 `task_in_epoch[epoch]` 中；如果需要在某个 epoch 之后执行，那么放入 `task_in_epoch[epoch + 1]` 中。
2. 对于所有 `normal_task` 中的任务，为其创建一个线程，将线程放入 `jobs_list` 中。
3. 对于每个 epoch，首先为 `task_in_epoch[epoch + 1]` 中的任务创建一个线程，然后将这个线程放入 `epoch_jobs_list` 中。把所有当前 epoch 的任务创建线程之后，依次 join 这些线程。并将 `epoch_jobs_list` 清空。
4. 依次将 `jobs_list` 执行 join 操作。

在线程安全的基础上，我们对于执行顺序的要求比较弱。具体来说，我们只保证每次读取和更新 embedding 是原子的（我们使用 `std::shared_mutex`，即读写锁来做到这一点），而不保证单个指令的执行过程中 embedding 不受其它线程的修改。由于机器学习任务的性质，我们认为这样做虽然会造成结果和原来的结果的差异，不会对算法的有效性和收敛性造成显著影响，并且我们观察到当放松执行顺序的要求之后，程序的性能得到了很大的提升。

此外，我们对单个指令的执行进行了一些并发优化，从而减少了它们的执行时间。具体优化方法如下：

1. 对于 `init` 操作，我们将所有的的 cold_start 操作并发执行，收集它们计算出的梯度，将这些梯度加起来，使用这一个梯度来进行更新。
2. 对于 `update` 操作，我们并发计算出 user 和 item 两个方向的梯度。
3. 对于 `recommend` 操作，由于它不涉及 slow_function，我们没有对其做特殊优化。

## 吐槽

本次作业所提供的实例代码不太让人满意，它存在以下一些问题：

1. 代码风格不一致，例如两格缩进和四格缩进混合。
2. 存在许多 C++ 不推荐的写法，包括：
   1. 在传入只读的变量的时候按值传递而非按引用传递参数；
   2. 许多能够标记为 const 的函数参数和成员函数没有被标注为 const；
   3. 使用 `push_back` 而非 `emplace_back`；
   4. 抛出的异常没有继承自 `std::exception`；
   5. 在返回值可以使用初始化列表初始化的时候使用先构造再传值的方法，导致可能多一次复制操作；
   6. 使用实例而不是类来访问静态方法；
   7. 定义 `to_string()` 函数而不是实现 `operator<<` 来实现字符串转换；单参数构造函数没有声明 explicit；

3. 大量使用裸指针和 `new` 关键词，在 `EmbeddingHolder` 和 `Embedding` 两个类中都使用了指针。用户需要手动管理变量的生命周期，从而造成了难以排查的内存泄漏问题。尤其是一些函数（例如 `calc_gradient`）的返回值也是指针。比较推荐的做法是直接使用值来传递函数的返回值，并且通过定义右值构造函数来避免数据的复制。

